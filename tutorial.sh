echo "document begins "	>> ./logs/gan.REC.mgan.g_lr.csv

#TUTORIAL of SGAN for emotion recognition experiments
#for sanity checks
#(1) audio and video
python sgan_mer.py -sm './model/gan.supervised.av.temp' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'
#(1-1) same but save the generated images
python sgan_mer.py -save_img './images/gan.supervised.av.temp' -sm './model/gan.supervised.av.temp' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#(2) audio only model by defining single modality in the model
python sgan_mer.py -sm './model/gan.supervised.a.temp' -mod a_feat -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D 3 -n_kernels_D 2,4,6 -cnn_n_row_D 16,32,64 -cnn_n_col_D 16,64,128 -pool_n_row_D 1,2,4 -pool_n_col_D 1,2,4 -r_nrow 100 -r_ncol 128 -depth_G 4 -n_kernels_G 4,64,32,1 -cnn_n_row_G 3,3,3,3 -cnn_n_col_G 3,3,3,3

#(2-1) audio only model by defining single modality in the model and single modality data from IEMOCAP
python sgan_mer.py -mod feat -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IEMOCAP.100.2d.10cc.4cls.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D 3 -n_kernels_D 2,4,6 -cnn_n_row_D 16,32,64 -cnn_n_col_D 16,64,128 -pool_n_row_D 1,2,4 -pool_n_col_D 1,2,4 -r_nrow 100 -r_ncol 128 -depth_G 4 -n_kernels_G 4,64,32,1 -cnn_n_row_G 3,3,3,3 -cnn_n_col_G 3,3,3,3

#(3) video only model by defining single modality in the model
python sgan_mer.py -sm './model/gan.supervised.v.temp' -mod v_feat -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D 3 -n_kernels_D 2,4,6 -cnn_n_row_D 8,16,32 -cnn_n_col_D 8,16,32 -pool_n_row_D 1,2,4 -pool_n_col_D 1,2,4 -r_nrow 48 -r_ncol 48 -depth_G 4 -n_kernels_G 4,64,32,1 -cnn_n_row_G 3,3,3,3 -cnn_n_col_G 3,3,3,3

#(4) unsupervised mode: audio and video
python sgan_mer.py -sm './model/gan.unsupervised.av.temp' -mod 'a_feat;v_feat' --unsupervised -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#(5) loading pre-trained av models: G only
python sgan_mer.py -lm_G './model/gan.supervised.av.temp.a_feat.generator;./model/gan.supervised.av.temp.v_feat.generator' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#(5-1) loading pre-trained av models: D only
python sgan_mer.py -lm_D './model/gan.supervised.av.temp.discriminator' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#(5-2) loading pre-trained av models: both G and D
python sgan_mer.py -lm_G './model/gan.supervised.av.temp.a_feat.generator;./model/gan.supervised.av.temp.v_feat.generator' -lm_D './model/gan.supervised.av.temp.discriminator' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#loading separately pre-trained a and v models: both G and D
#(5-3) for D, load only an audio part
python sgan_mer.py -lm_G './model/gan.supervised.a.temp.a_feat.generator;./model/gan.supervised.v.temp.v_feat.generator' -lm_D './model/gan.supervised.a.temp.discriminator' -unloaded_D '33:38' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'
#(5-4) for D, load only a video part
python sgan_mer.py -lm_G './model/gan.supervised.a.temp.a_feat.generator;./model/gan.supervised.v.temp.v_feat.generator' -lm_D './model/gan.supervised.v.temp.discriminator' -unloaded_D '33:38' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'
#(5-5) for D, load both audio and video parts from different models
python sgan_mer.py -lm_G './model/gan.supervised.a.temp.a_feat.generator;./model/gan.supervised.v.temp.v_feat.generator' -lm_D './model/gan.supervised.a.temp.discriminator;./model/gan.supervised.v.temp.discriminator' -unloaded_D '33:38;33:38' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#(5-6) loading pre-trained unsupervised av models: both G and D
python sgan_mer.py -lm_G './model/gan.unsupervised.av.temp.a_feat.generator;./model/gan.unsupervised.av.temp.v_feat.generator' -lm_D './model/gan.unsupervised.av.temp.discriminator' -mod 'a_feat;v_feat' -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 1 -n_node 256 -task_weights 0.5,0.5 -test_idx 0 -valid_idx 1 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.IMG.100.2d.cc.REC.4cls.av.h5 -mt valence:3:5:: -log ./logs/gan.REC.mgan.g_lr.csv -depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'

#(6) train other corpora in unsupervised mode
python sgan_mer.py -sm './model/sgan/gan.unsupervised.LSPEC.100.2d.si.AEFILSR.audio.4cls' -save_img './images/gan.unsupervised.LSPEC.100.2d.si.AEFILSR.4cls' -mod feat --unsupervised -p 15 -d_lr 0.000005 -g_lr 0.00002 -check_batch_interval 10 -save_img_interval 1 -b 128 -e 100 -depth_D 3 -n_node 512 -n_kernels_D 4,8,12 -cnn_n_row_D 16,32,64 -cnn_n_col_D 16,64,128 -pool_n_row_D 1,2,4 -pool_n_col_D 1,2,4 -r_nrow 100 -r_ncol 128 -task_weights 0.5,0.5 -depth_G 4 -n_kernels_G 4,64,32,1 -cnn_n_row_G 3,3,3,3 -cnn_n_col_G 3,3,3,3 -test_idx 111:130 -valid_idx 111:130 -dt ../../features/ser/stl_vs_mtl/lstm/LSPEC.100.2d.si.AEFILSR.4cls.h5 -log ./logs/gan.AEFILSR.unsupervised.csv 

#single modality options
#-depth_D 3 -n_kernels_D 2,4,6 -cnn_n_row_D 16,32,64 -cnn_n_col_D 16,64,128 -pool_n_row_D 1,2,4 -pool_n_col_D 1,2,4 -r_nrow 100 -r_ncol 128 -depth_G 4 -n_kernels_G 4,64,32,1 -cnn_n_row_G 3,3,3,3 -cnn_n_col_G 3,3,3,3

#multi modality options
#-depth_D '3;3' -n_kernels_D '2,4,6;2,4,6' -cnn_n_row_D '16,32,64;8,16,32' -cnn_n_col_D '16,64,128;8,16,32' -pool_n_row_D '1,2,4;1,2,4' -pool_n_col_D '1,2,4;1,2,4' -r_nrow '100;48' -r_ncol '128;48' -depth_G '4;4' -n_kernels_G '4,64,32,1;4,64,32,1' -cnn_n_row_G '3,3,3,3;3,3,3,3' -cnn_n_col_G '3,3,3,3;3,3,3,3'
